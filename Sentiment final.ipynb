{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Twitter Comments Scrapper\nimport sys,tweepy,csv,re\nfrom textblob import TextBlob\nimport matplotlib.pyplot as plt\n\n\nclass SentimentAnalysis:\n\n    def __init__(self):\n        self.tweets = []\n        self.tweetText = []\n\n    def DownloadData(self):\n        # authenticating\n        consumerKey = '667OOi8BcK8R2gNOJNecmuOra'\n        consumerSecret = 'Wxhhv1dH5TAyrtBVKBjNg52vGyzL3YGbYRVGkZ0ChfFpsXJyR6'\n        accessToken = '1193971945764769793-sCKnrMI4zFyrUY20uK5IssFXGVgyZI'\n        accessTokenSecret = 'fzYut9SWq7ZbeIlJwuLYeoe370enzwktM4vQlHK0UtsgM'\n        auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n        auth.set_access_token(accessToken, accessTokenSecret)\n        api = tweepy.API(auth)\n\n        # input for term to be searched and how many tweets to search\n        searchTerm = input(\"Enter Keyword/Tag to search about: \")\n        NoOfTerms = int(input(\"Enter how many tweets to search: \"))\n\n        # searching for tweets\n        self.tweets = tweepy.Cursor(api.search, q=searchTerm, lang = \"en\").items(NoOfTerms)\n\n       # Open/create a file to append data to\n        csvFile = open('NNNNNN.csv', 'w')\n\n        \n\n        # creating some variables to store info\n        polarity = 0\n        positive = 0\n        wpositive = 0\n        spositive = 0\n        negative = 0\n        wnegative = 0\n        snegative = 0\n        neutral = 0\n\n\n        # iterating through tweets fetched\n        for tweet in self.tweets:\n            #Append to temp so that we can store in csv later. I use encode UTF-8\n            csvFile.write(tweet.text)\n            csvFile.write(\"\\n\")\n            # print (tweet.text.translate(non_bmp_map))    #print tweet's text\n            analysis = TextBlob(tweet.text)\n            # print(analysis.sentiment)  # print tweet's polarity\n            polarity += analysis.sentiment.polarity  # adding up polarities to find the average later\n\n            if (analysis.sentiment.polarity == 0):  # adding reaction of how people are reacting to find average later\n                neutral += 1\n            elif (analysis.sentiment.polarity > 0 and analysis.sentiment.polarity <= 0.3):\n                wpositive += 1\n            elif (analysis.sentiment.polarity > 0.3 and analysis.sentiment.polarity <= 0.6):\n                positive += 1\n            elif (analysis.sentiment.polarity > 0.6 and analysis.sentiment.polarity <= 1):\n                spositive += 1\n            elif (analysis.sentiment.polarity > -0.3 and analysis.sentiment.polarity <= 0):\n                wnegative += 1\n            elif (analysis.sentiment.polarity > -0.6 and analysis.sentiment.polarity <= -0.3):\n                negative += 1\n            elif (analysis.sentiment.polarity > -1 and analysis.sentiment.polarity <= -0.6):\n                snegative += 1\n\n\n        # Write to csv and close csv file\n        \n        csvFile.close()\n\n\n        # finding average of how people are reacting\n        positive = self.percentage(positive, NoOfTerms)\n        wpositive = self.percentage(wpositive, NoOfTerms)\n        spositive = self.percentage(spositive, NoOfTerms)\n        negative = self.percentage(negative, NoOfTerms)\n        wnegative = self.percentage(wnegative, NoOfTerms)\n        snegative = self.percentage(snegative, NoOfTerms)\n        neutral = self.percentage(neutral, NoOfTerms)\n\n        # finding average reaction\n        polarity = polarity / NoOfTerms\n\n        # printing out data\n        print(\"How people are reacting on \" + searchTerm + \" by analyzing \" + str(NoOfTerms) + \" tweets.\")\n        print()\n        print(\"General Report: \")\n\n        if (polarity == 0):\n            print(\"Neutral\")\n        elif (polarity > 0 and polarity <= 0.3):\n            print(\"Weakly Positive\")\n        elif (polarity > 0.3 and polarity <= 0.6):\n            print(\"Positive\")\n        elif (polarity > 0.6 and polarity <= 1):\n            print(\"Strongly Positive\")\n        elif (polarity > -0.3 and polarity <= 0):\n            print(\"Weakly Negative\")\n        elif (polarity > -0.6 and polarity <= -0.3):\n            print(\"Negative\")\n        elif (polarity > -1 and polarity <= -0.6):\n            print(\"Strongly Negative\")\n\n        print()\n        print(\"Detailed Report: \")\n        print(str(positive) + \"% people thought it was positive\")\n        print(str(wpositive) + \"% people thought it was weakly positive\")\n        print(str(spositive) + \"% people thought it was strongly positive\")\n        print(str(negative) + \"% people thought it was negative\")\n        print(str(wnegative) + \"% people thought it was weakly negative\")\n        print(str(snegative) + \"% people thought it was strongly negative\")\n        print(str(neutral) + \"% people thought it was neutral\")\n\n        self.plotPieChart(positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, NoOfTerms)\n\n\n    def cleanTweet(self, tweet):\n        # Remove Links, Special Characters etc from tweet\n        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) | (\\w +:\\ / \\ / \\S +)\", \" \", tweet).split())\n\n    # function to calculate percentage\n    def percentage(self, part, whole):\n        temp = 100 * float(part) / float(whole)\n        return format(temp, '.2f')\n\n    def plotPieChart(self, positive, wpositive, spositive, negative, wnegative, snegative, neutral, searchTerm, noOfSearchTerms):\n        labels = ['Positive [' + str(positive) + '%]', 'Weakly Positive [' + str(wpositive) + '%]','Strongly Positive [' + str(spositive) + '%]', 'Neutral [' + str(neutral) + '%]',\n                  'Negative [' + str(negative) + '%]', 'Weakly Negative [' + str(wnegative) + '%]', 'Strongly Negative [' + str(snegative) + '%]']\n        sizes = [positive, wpositive, spositive, neutral, negative, wnegative, snegative]\n        colors = ['yellowgreen','lightgreen','darkgreen', 'gold', 'red','lightsalmon','darkred']\n        patches, texts = plt.pie(sizes, colors=colors, startangle=90)\n        plt.legend(patches, labels, loc=\"best\")\n        plt.title('How people are reacting on ' + searchTerm + ' by analyzing ' + str(noOfSearchTerms) + ' Tweets.')\n        plt.axis('equal')\n        plt.tight_layout()\n        plt.show()\n\n\n\nif __name__== \"__main__\":\n    sa = SentimentAnalysis()\n    sa.DownloadData()\n    \n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    \n#Youtube Scripts Scrapper\n\nimport requests\nimport time\nimport sys\nimport progressbar as PB\nfrom nlppreprocess import NLP # for text cleaning\n\nYOUTUBE_IN_LINK = 'https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&maxResults=100&order=relevance&pageToken={pageToken}&videoId={videoId}&key={key}'\nYOUTUBE_LINK = 'https://www.googleapis.com/youtube/v3/commentThreads?part=snippet&maxResults=100&order=relevance&videoId={videoId}&key={key}'\nkey = 'AIzaSyAVfg14R8T1w75So5I7Wt3zsQ9zdRAhvKo'\n\t\n\ndef Extract(videoId, count = -1):\n\tprint (\"Comments downloading\")\n\tpage_info = requests.get(YOUTUBE_LINK.format(videoId = videoId, key = key))\n\twhile page_info.status_code != 200:\n\t\tif page_info.status_code != 429:\n\t\t\tprint (\"Comments disabled\")\n\t\t\tsys.exit()\n\n\t\ttime.sleep(20)\n\t\tpage_info = requests.get(YOUTUBE_LINK.format(videoId = videoId, key = key))\n\n\tpage_info = page_info.json()\n\n\tcomments = []\n\tco = 0;\n\tfor i in range(len(page_info['items'])):\n\t\tcomments.append(page_info['items'][i]['snippet']['topLevelComment']['snippet']['textOriginal'])\n\t\tco += 1\n\t\tif co == count:\n\t\t\tPB.ProgressBar(co, count)\n\t\t\treturn comments\n\n\tPB.ProgressBar(co, count)\n\t# INFINTE SCROLLING\n\twhile 'nextPageToken' in page_info:\n\t\ttemp = page_info\n\t\tpage_info = requests.get(YOUTUBE_IN_LINK.format(videoId = videoId, key = key, pageToken = page_info['nextPageToken']))\n\n\t\twhile page_info.status_code != 200:\n\t\t\ttime.sleep(20)\n\t\t\tpage_info = requests.get(YOUTUBE_IN_LINK.format(videoId = videoId, key = key, pageToken = temp['nextPageToken']))\n\t\tpage_info = page_info.json()\n\n\t\tfor i in range(len(page_info['items'])):\n\t\t\tcomments.append(page_info['items'][i]['snippet']['topLevelComment']['snippet']['textOriginal'])\n\t\t\tco += 1\n\t\t\tif co == count:\n\t\t\t\tPB.progressbar(co, count, cond = True)\n\t\t\t\treturn comments\n\t\tPB.progressbar(co, count)\n\tPB.progressbar(count, count, cond = True)\n\tprint ()\n\n\treturn comments\n\n# provide link of that video you want to extract comments \n\nlink='https://www.youtube.com/watch?v=WpPw7lUXyI0'     #links can be changed according to the particular phone review\nid_1=link.split(\"v=\",1)[1]\n\n# give the no of comments \nno_of_comments=400\n\nobj = NLP()# creating an object for text cleaning\n\n\n# data in the form of a pandas dataframe and it is a list of comments\ncomment_list=Extract(id_1,no_of_comments)\n\n# getting data in your desireable form like .csv, .txt  .docx \n# just change the extension of filename below to get your desired format\n\nfilename= 'K20.csv'\noutput_file= open(filename, 'w',encoding='utf-8')\n\nfor comment in comment_list:\n    text=obj.process(comment)\n    output_file.write(text)\n    output_file.write('\\n')\noutput_file.close()\n\n\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adjectives Cloud creation \n\n\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\nimport numpy as np\n\nimport pandas as pd\nds=pd.read_csv(\"/home/parth/Downloads/Harsha assignment/NNNNNN.csv\",error_bad_lines=False)  #reading the comments csv file of particular phone\ndf=ds.iloc[:,:].values\ndf=np.array(df)\ndf=df.flatten()\nl=[]\nfor i in df:\n    doc = nlp(i)\n    for token in doc:\n        if  (token.pos_==\"ADJ\"):               #checking the words as adjectives\n            l.append(token)\n            \n#converting data type from spacy.token to string\nfor i in range(0,len(l)):\n    l[i]=str(l[i])\n\nf=open(\"NNNNN_cloud.csv\", \"w+\",encoding=\"UTF-8\")             #opening files for saving cloud data\nfor i in l:\n     f.write(i)\n     f.write(\"\\n\")\n\n     \nf.close() ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing comments csv files and testing sentiment analysis\n\n\nimport numpy as np\n\nimport pandas as pd\nds=pd.read_csv(\"/home/parth/Downloads/Harsha assignment/NNNNN_cloud.csv\")\ndf=ds.iloc[:,:].values\ndf=np.array(df)\ndf=df.flatten()\nfrom textblob import TextBlob\npolarity = 0\npositive = 0\nwpositive = 0\nspositive = 0\nnegative = 0\nwnegative = 0\nsnegative = 0\nneutral = 0\n\nNoOfTerms=len(df)\n\nfor i in df:\n    \n    analysis = TextBlob(i)\n    \n    # print comment's polarity\n    polarity += analysis.sentiment.polarity  \n    \n    # adding up polarities to find the average later\n\n    if (analysis.sentiment.polarity == 0):  # adding reaction of how people are reacting to find average later\n                neutral += 1\n    elif (analysis.sentiment.polarity > 0 and analysis.sentiment.polarity <= 0.3):\n                positive += 1\n    elif (analysis.sentiment.polarity > 0.3 and analysis.sentiment.polarity <= 0.6):\n                positive += 1\n    elif (analysis.sentiment.polarity > 0.6 and analysis.sentiment.polarity <= 1):\n                positive += 1\n    elif (analysis.sentiment.polarity > -0.3 and analysis.sentiment.polarity <= 0):\n                negative += 1\n    elif (analysis.sentiment.polarity > -0.6 and analysis.sentiment.polarity <= -0.3):\n                negative += 1\n    elif (analysis.sentiment.polarity > -1 and analysis.sentiment.polarity <= -0.6):\n                negative += 1\n\ndef percentage(part, whole):\n        temp = 100 * float(part) / float(whole)\n        return format(temp, '.2f')\n    \n\n\n# finding average of how people are reacting\npositive = percentage(positive, NoOfTerms)\nwpositive = percentage(wpositive, NoOfTerms)\nspositive = percentage(spositive, NoOfTerms)\nnegative = percentage(negative, NoOfTerms)\nwnegative = percentage(wnegative, NoOfTerms)\nsnegative = percentage(snegative, NoOfTerms)\nneutral = percentage(neutral, NoOfTerms)\n\n# finding average reaction\npolarity = polarity / NoOfTerms\n\n\nprint()\nprint(\"Detailed Report: \")\nprint(str(positive) + \"% people thought it was positive\")\nprint(str(wpositive) + \"% people thought it was weakly positive\")\nprint(str(spositive) + \"% people thought it was strongly positive\")\nprint(str(negative) + \"% people thought it was negative\")\nprint(str(wnegative) + \"% people thought it was weakly negative\")\nprint(str(snegative) + \"% people thought it was strongly negative\")\nprint(str(neutral) + \"% people thought it was neutral\")","metadata":{},"execution_count":null,"outputs":[]}]}